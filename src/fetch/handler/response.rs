//! HTTP response handling.

use anyhow::{Error, Result};
use log::debug;

use crate::fetch::dns::fetch_all_dns_data;
use crate::fetch::record::prepare_record_for_insertion;
use crate::fetch::response::{extract_response_data, parse_html_content};
use crate::fetch::ProcessingContext;
use crate::storage::insert::insert_batch_record;
use crate::utils::{duration_to_ms, UrlTimingMetrics};
use std::time::Instant;

/// Handles an HTTP response, extracting all relevant data and storing it in the database.
///
/// This function orchestrates domain extraction, TLS certificate retrieval, DNS lookups,
/// HTML parsing, and database insertion.
///
/// # Arguments
///
/// * `response` - The HTTP response
/// * `original_url` - The original URL before redirects
/// * `final_url_str` - The final URL after redirects
/// * `ctx` - Processing context containing all shared resources
/// * `elapsed` - Response time in seconds (includes redirect resolution + HTTP request)
/// * `redirect_chain` - Vector of redirect chain URLs (will be inserted into url_redirect_chain table)
/// * `start_time` - Original start time from process_url (for accurate total_ms calculation)
///
/// # Errors
///
/// Returns an error if domain extraction, DNS resolution, or database insertion fails.
pub async fn handle_response(
    response: reqwest::Response,
    original_url: &str,
    final_url_str: &str,
    ctx: &ProcessingContext,
    elapsed: f64,
    redirect_chain: Option<Vec<String>>,
    start_time: std::time::Instant,
) -> Result<(), Error> {
    // Use start_time for total_ms calculation to ensure accurate percentages
    // This ensures http_request_ms (which includes redirect resolution) is <= total_ms
    // since both are measured from the same start point
    debug!("Started processing response for {final_url_str}");

    let mut metrics = UrlTimingMetrics {
        // elapsed is in seconds, convert to microseconds for internal storage
        // Note: This includes redirect resolution time + HTTP request time
        // Use saturating cast to prevent overflow if elapsed is very large
        // Max safe value: ~18,446 seconds (u64::MAX microseconds) before overflow
        // NOTE: Field is named `_ms` but actually stores microseconds (Î¼s) for precision
        // This is a naming legacy - all timing fields store microseconds internally
        http_request_ms: (elapsed * 1_000_000.0).min(u64::MAX as f64).max(0.0) as u64,
        ..Default::default()
    };

    // Extract and validate response data
    let html_parse_start = Instant::now();
    let Some(resp_data) = extract_response_data(
        response,
        original_url,
        final_url_str,
        &ctx.network.extractor,
    )
    .await?
    else {
        // Non-HTML or empty response, skip silently
        // This is logged at debug level in extract_response_data
        debug!(
            "Skipping URL {} (non-HTML content-type, empty body, or body too large)",
            final_url_str
        );
        return Ok(());
    };

    // Parse HTML content
    let html_data = parse_html_content(
        &resp_data.body,
        &resp_data.final_domain,
        &ctx.config.error_stats,
    );
    metrics.html_parsing_ms = duration_to_ms(html_parse_start.elapsed());

    // Run tech detection and DNS/TLS in parallel (they're independent)
    // Tech detection only needs HTML data and headers, DNS/TLS only needs domain
    let timestamp = chrono::Utc::now().timestamp_millis();
    let redirect_chain_vec = redirect_chain.unwrap_or_default();

    let (tech_result, dns_result) = tokio::join!(
        // Technology detection (only needs HTML data and headers)
        async {
            use crate::fetch::record::detect_technologies_safely;
            use crate::utils::duration_to_ms;
            use std::time::Instant;

            let tech_start = Instant::now();
            let technologies =
                detect_technologies_safely(&html_data, &resp_data, &ctx.config.error_stats).await;
            let tech_detection_ms = duration_to_ms(tech_start.elapsed());
            (technologies, tech_detection_ms)
        },
        // DNS/TLS fetching (only needs domain/hostname)
        async {
            fetch_all_dns_data(
                &resp_data,
                &ctx.network.resolver,
                &ctx.config.error_stats,
                ctx.config.run_id.as_deref(),
            )
            .await
        }
    );

    let (technologies_vec, tech_detection_ms) = tech_result;
    let (
        tls_dns_data,
        additional_dns,
        partial_failures,
        (dns_forward_ms, dns_reverse_ms, dns_additional_ms, tls_handshake_ms),
    ) = dns_result?;

    metrics.dns_forward_ms = dns_forward_ms;
    metrics.dns_reverse_ms = dns_reverse_ms;
    metrics.dns_additional_ms = dns_additional_ms;
    metrics.tls_handshake_ms = tls_handshake_ms;
    metrics.tech_detection_ms = tech_detection_ms;

    debug!(
        "Preparing to insert record for URL: {}",
        resp_data.final_url
    );
    log::debug!(
        "Attempting to insert record into database for domain: {}",
        resp_data.initial_domain
    );

    // Prepare record for insertion (enrichment lookups and batch record building)
    let (batch_record, (geoip_lookup_ms, whois_lookup_ms, security_analysis_ms)) =
        prepare_record_for_insertion(crate::fetch::record::RecordPreparationParams {
            resp_data: &resp_data,
            html_data: &html_data,
            tls_dns_data: &tls_dns_data,
            additional_dns: &additional_dns,
            technologies_vec,
            partial_failures,
            redirect_chain: redirect_chain_vec,
            elapsed,
            timestamp,
            ctx,
        })
        .await;

    metrics.geoip_lookup_ms = geoip_lookup_ms;
    metrics.whois_lookup_ms = whois_lookup_ms;
    metrics.security_analysis_ms = security_analysis_ms;

    // Insert record directly into database
    // If write fails, return error so URL is not counted as successful
    // Database errors are non-retriable, so this won't trigger retries
    insert_batch_record(&ctx.db.pool, batch_record)
        .await
        .map_err(|e| {
            log::error!(
                "Failed to insert record for URL {}: {}",
                resp_data.final_url,
                e
            );
            anyhow::anyhow!("Database write failed: {}", e)
        })?;

    // Calculate total_ms from start_time (same baseline as http_request_ms)
    // This ensures percentages are accurate (http_request_ms <= total_ms)
    metrics.total_ms = duration_to_ms(start_time.elapsed());

    // Record metrics (DNS and enrichment times are set inside their respective functions)
    ctx.config.timing_stats.record(&metrics);

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::error_handling::ProcessingStats;
    use crate::fetch::context::ProcessingContext;
    use crate::storage::circuit_breaker::DbWriteCircuitBreaker;
    use crate::utils::TimingStats;
    use hickory_resolver::{config::ResolverOpts, TokioResolver};
    use httptest::{matchers::*, responders::*, Expectation, Server};
    use std::sync::Arc;

    async fn create_test_context(_server: &Server) -> ProcessingContext {
        let client = Arc::new(
            reqwest::Client::builder()
                .timeout(std::time::Duration::from_secs(5))
                .build()
                .expect("Failed to create HTTP client"),
        );
        let redirect_client = Arc::new(
            reqwest::Client::builder()
                .redirect(reqwest::redirect::Policy::none())
                .timeout(std::time::Duration::from_secs(5))
                .build()
                .expect("Failed to create redirect client"),
        );
        let extractor = Arc::new(psl::List);
        let resolver = Arc::new(
            TokioResolver::builder_tokio()
                .unwrap()
                .with_options(ResolverOpts::default())
                .build(),
        );
        let error_stats = Arc::new(ProcessingStats::new());
        let timing_stats = Arc::new(TimingStats::new());
        let db_circuit_breaker = Arc::new(DbWriteCircuitBreaker::default());
        let pool = Arc::new(
            sqlx::SqlitePool::connect("sqlite::memory:")
                .await
                .expect("Failed to create test pool"),
        );

        ProcessingContext::new(
            client,
            redirect_client,
            extractor,
            resolver,
            error_stats,
            None,
            false,
            db_circuit_breaker,
            pool,
            timing_stats,
        )
    }

    #[tokio::test]
    async fn test_handle_response_non_html_skips_silently() {
        let server = Server::run();
        let server_url = server.url("/json").to_string();
        let original_url = "https://example.com/json";

        // Return JSON instead of HTML
        server.expect(
            Expectation::matching(request::method_path("GET", "/json")).respond_with(
                status_code(200)
                    .insert_header("Content-Type", "application/json")
                    .body(r#"{"key": "value"}"#),
            ),
        );

        let client = reqwest::Client::new();
        let response = client.get(&server_url).send().await.unwrap();
        let ctx = create_test_context(&server).await;
        let start_time = std::time::Instant::now();

        // Non-HTML responses should return Ok(()) silently
        // Note: Domain extraction may fail for IP addresses from httptest,
        // but if it succeeds, non-HTML content should be skipped
        let result = handle_response(
            response,
            original_url,
            &server_url,
            &ctx,
            0.1,
            None,
            start_time,
        )
        .await;

        // Should succeed (skip silently) OR fail at domain extraction (both are acceptable)
        // The key is that if extract_response_data returns Ok(None), handle_response returns Ok(())
        match result {
            Ok(()) => {
                // Success - non-HTML was skipped silently
            }
            Err(e) => {
                // Domain extraction failed (expected for IP addresses)
                let error_msg = e.to_string();
                assert!(
                    error_msg.contains("domain")
                        || error_msg.contains("Failed to extract")
                        || error_msg.contains("IP addresses"),
                    "Expected domain extraction error, got: {}",
                    error_msg
                );
            }
        }
    }

    #[tokio::test]
    async fn test_handle_response_empty_body_skips_silently() {
        let server = Server::run();
        let server_url = server.url("/empty").to_string();
        let original_url = "https://example.com/empty";

        // Return empty body
        server.expect(
            Expectation::matching(request::method_path("GET", "/empty")).respond_with(
                status_code(200)
                    .insert_header("Content-Type", "text/html; charset=utf-8")
                    .body(""),
            ),
        );

        let client = reqwest::Client::new();
        let response = client.get(&server_url).send().await.unwrap();
        let ctx = create_test_context(&server).await;
        let start_time = std::time::Instant::now();

        // Empty responses should return Ok(()) silently
        // Note: Domain extraction may fail for IP addresses from httptest,
        // but if it succeeds, empty body should be skipped
        let result = handle_response(
            response,
            original_url,
            &server_url,
            &ctx,
            0.1,
            None,
            start_time,
        )
        .await;

        // Should succeed (skip silently) OR fail at domain extraction (both are acceptable)
        // The key is that if extract_response_data returns Ok(None), handle_response returns Ok(())
        match result {
            Ok(()) => {
                // Success - empty body was skipped silently
            }
            Err(e) => {
                // Domain extraction failed (expected for IP addresses)
                let error_msg = e.to_string();
                assert!(
                    error_msg.contains("domain")
                        || error_msg.contains("Failed to extract")
                        || error_msg.contains("IP addresses"),
                    "Expected domain extraction error, got: {}",
                    error_msg
                );
            }
        }
    }

    #[tokio::test]
    async fn test_handle_response_dns_failure_propagates_error() {
        let server = Server::run();
        let server_url = server.url("/test").to_string();
        let original_url = "https://this-domain-definitely-does-not-exist-12345.invalid/test";

        // Return valid HTML
        server.expect(
            Expectation::matching(request::method_path("GET", "/test")).respond_with(
                status_code(200)
                    .insert_header("Content-Type", "text/html; charset=utf-8")
                    .body("<html><head><title>Test</title></head><body>Hello</body></html>"),
            ),
        );

        let client = reqwest::Client::new();
        let response = client.get(&server_url).send().await.unwrap();
        let ctx = create_test_context(&server).await;
        let start_time = std::time::Instant::now();

        // DNS failure should propagate (domain extraction will fail first, but if it succeeds,
        // DNS lookup will fail for invalid domain)
        let result = handle_response(
            response,
            original_url,
            &server_url,
            &ctx,
            0.1,
            None,
            start_time,
        )
        .await;

        // Should fail - either domain extraction or DNS lookup
        assert!(result.is_err());
        let error_msg = result.unwrap_err().to_string();
        assert!(
            error_msg.contains("Failed to extract")
                || error_msg.contains("domain")
                || error_msg.contains("DNS")
                || error_msg.contains("Database write failed"), // Or database error if migrations missing
            "Expected domain/DNS/database error, got: {}",
            error_msg
        );
    }

    #[tokio::test]
    async fn test_handle_response_metrics_recorded() {
        let server = Server::run();
        let server_url = server.url("/metrics").to_string();
        let original_url = "https://example.com/metrics";

        // Return valid HTML
        server.expect(
            Expectation::matching(request::method_path("GET", "/metrics")).respond_with(
                status_code(200)
                    .insert_header("Content-Type", "text/html; charset=utf-8")
                    .body("<html><head><title>Test</title></head><body>Hello</body></html>"),
            ),
        );

        let client = reqwest::Client::new();
        let response = client.get(&server_url).send().await.unwrap();
        let ctx = create_test_context(&server).await;
        let start_time = std::time::Instant::now();

        // This will likely fail at database insertion (migrations not set up),
        // but metrics should be calculated before that
        let _result = handle_response(
            response,
            original_url,
            &server_url,
            &ctx,
            0.1,
            None,
            start_time,
        )
        .await;

        // Verify timing stats were accessed (even if insertion failed)
        // The timing_stats.record() call should have been made
        // We can't easily verify the internal state, but we can verify it didn't panic
    }

    #[tokio::test]
    async fn test_handle_response_redirect_chain_preserved() {
        let server = Server::run();
        let server_url = server.url("/redirected").to_string();
        let original_url = "https://example.com/original";
        let redirect_chain = Some(vec![
            "https://example.com/original".to_string(),
            "https://example.com/intermediate".to_string(),
            server_url.clone(),
        ]);

        // Return valid HTML
        server.expect(
            Expectation::matching(request::method_path("GET", "/redirected")).respond_with(
                status_code(200)
                    .insert_header("Content-Type", "text/html; charset=utf-8")
                    .body("<html><head><title>Test</title></head><body>Hello</body></html>"),
            ),
        );

        let client = reqwest::Client::new();
        let response = client.get(&server_url).send().await.unwrap();
        let ctx = create_test_context(&server).await;
        let start_time = std::time::Instant::now();

        // Redirect chain should be preserved through processing
        let _result = handle_response(
            response,
            original_url,
            &server_url,
            &ctx,
            0.1,
            redirect_chain.clone(),
            start_time,
        )
        .await;

        // Verify redirect chain was passed through (will be in database if insertion succeeds)
        // For now, just verify it doesn't panic
    }

    #[tokio::test]
    async fn test_handle_response_negative_elapsed_time() {
        // Test that negative elapsed time is handled gracefully (should be clamped to 0)
        let server = Server::run();
        let server_url = server.url("/").to_string();

        server.expect(
            Expectation::matching(request::method_path("GET", "/")).respond_with(
                status_code(200)
                    .insert_header("Content-Type", "text/html; charset=utf-8")
                    .body("<html><head><title>Test</title></head></html>"),
            ),
        );

        let client = reqwest::Client::new();
        let response = client.get(&server_url).send().await.unwrap();
        let ctx = create_test_context(&server).await;
        let start_time = std::time::Instant::now();

        // Negative elapsed time should be clamped to 0
        let result = handle_response(
            response,
            "https://example.com",
            &server_url,
            &ctx,
            -1.0, // Negative elapsed time
            None,
            start_time,
        )
        .await;

        // Should handle gracefully (may fail at domain extraction or succeed)
        // The key is that negative elapsed is clamped to 0 in metrics calculation
        let _ = result;
    }

    #[tokio::test]
    async fn test_handle_response_very_large_elapsed_time() {
        // Test that very large elapsed time doesn't cause overflow
        let server = Server::run();
        let server_url = server.url("/").to_string();

        server.expect(
            Expectation::matching(request::method_path("GET", "/")).respond_with(
                status_code(200)
                    .insert_header("Content-Type", "text/html; charset=utf-8")
                    .body("<html><head><title>Test</title></head></html>"),
            ),
        );

        let client = reqwest::Client::new();
        let response = client.get(&server_url).send().await.unwrap();
        let ctx = create_test_context(&server).await;
        let start_time = std::time::Instant::now();

        // Very large elapsed time (would overflow u64::MAX microseconds)
        let very_large_elapsed = 20_000.0; // 20,000 seconds
        let result = handle_response(
            response,
            "https://example.com",
            &server_url,
            &ctx,
            very_large_elapsed,
            None,
            start_time,
        )
        .await;

        // Should handle gracefully (clamped to u64::MAX)
        // May fail at domain extraction, but shouldn't panic on overflow
        let _ = result;
    }

    #[tokio::test]
    async fn test_handle_response_timing_consistency() {
        // Test that http_request_ms <= total_ms (critical for percentage accuracy)
        let server = Server::run();
        let server_url = server.url("/").to_string();

        server.expect(
            Expectation::matching(request::method_path("GET", "/")).respond_with(
                status_code(200)
                    .insert_header("Content-Type", "text/html; charset=utf-8")
                    .body("<html><head><title>Test</title></head></html>"),
            ),
        );

        let client = reqwest::Client::new();
        let response = client.get(&server_url).send().await.unwrap();
        let ctx = create_test_context(&server).await;
        let start_time = std::time::Instant::now();

        // Use a reasonable elapsed time
        let elapsed = 0.5; // 500ms
        let result = handle_response(
            response,
            "https://example.com",
            &server_url,
            &ctx,
            elapsed,
            None,
            start_time,
        )
        .await;

        // If successful, timing stats should have been recorded
        // The key invariant: http_request_ms (from elapsed) should be <= total_ms (from start_time.elapsed())
        // This is ensured by using the same start_time baseline
        // We can't easily verify the exact values without accessing internal state,
        // but we verify the function doesn't panic and handles timing correctly
        let _ = result;
    }

    #[tokio::test]
    async fn test_handle_response_timing_metrics_overflow_protection() {
        // Test that very large elapsed times don't cause overflow
        // This is critical - elapsed * 1_000_000.0 could overflow u64
        // The code at line 53 uses .min(u64::MAX as f64) to prevent overflow
        let very_large_elapsed = 1_000_000.0; // 1 million seconds

        // Verify the calculation doesn't panic
        let http_request_ms: f64 = very_large_elapsed * 1_000_000.0;
        let http_request_ms = http_request_ms.min(u64::MAX as f64).max(0.0) as u64;
        // With protection, should be clamped to u64::MAX (not overflow)
        // Note: Due to floating point precision, might be slightly less than MAX
        // The important thing is it doesn't overflow and is a very large value
        assert!(http_request_ms >= 1_000_000_000_000_000);
    }

    #[tokio::test]
    async fn test_handle_response_negative_elapsed_clamped() {
        // Test that negative elapsed times are clamped to 0
        // This is critical - clock adjustments could cause negative elapsed
        // The code at line 53 uses .max(0.0) to prevent negative values
        let negative_elapsed = -1.0;

        // Verify the calculation clamps negative values
        let http_request_ms: f64 = negative_elapsed * 1_000_000.0;
        let http_request_ms = http_request_ms.min(u64::MAX as f64).max(0.0) as u64;
        // Should be clamped to 0, not negative
        assert_eq!(http_request_ms, 0);
    }
}
